{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REAL TIME PITCH SHIFTING "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 1: INTRODUCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This notebook presents several techniques to perform pitch shifting in real time.\n",
    "Concretely, the goal is to transform in real time the voice of a person by making it deeper.**\n",
    "\n",
    "**In particular this notebook will explore the robot voice technique, the basic granular synthesis algorithm and finally a more advanced version of the latter that uses LPC.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Of course, it is obviously impossible to achieve pure real time (ie bit per bit) processing. The data will be processed using buffers of the smallest size as possible.**\n",
    "\n",
    "So, the main problem induced by the real time approach is that the processing has to be very efficient so that there is no big delay between input and output signals. To face this constraint there are a few things that must be done:\n",
    "    1. using integers value as much as possible.\n",
    "    2. using precomputed look-up-table (LUT) to avoid useless repetive computations.\n",
    "    3. coding as in C (close to the machine)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need the following libraries to handle all the audio processing to come:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sounddevice as sd\n",
    "from scipy.io import wavfile\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.signal as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 2: ROBOT VOICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a SIN table ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### text about sin table, explain why this is a constant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function precomputes the SIN table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define necessary utility functions\n",
    "def build_sine_table(f_sine, samp_freq, data_type):\n",
    "    \n",
    "    \n",
    "    # compute the integer conversion parameters\n",
    "    if data_type == np.int16:\n",
    "        MAX_SINE = 2**(15)-1\n",
    "    elif data_type == np.int32:\n",
    "        MAX_SINE = 2**(31)-1\n",
    "    \n",
    "    # periods\n",
    "    samp_per = 1./samp_freq\n",
    "    sine_per = 1./f_sine\n",
    "\n",
    "    # compute the right number of (integer) time instances\n",
    "    LOOKUP_SIZE = len(np.arange(0, sine_per, samp_per))\n",
    "    n = np.arange(LOOKUP_SIZE)\n",
    "    \n",
    "    \n",
    "    freq_step = f_sine/samp_freq\n",
    "    SINE_TABLE = np.sin(2*np.pi*n*freq_step) * MAX_SINE\n",
    "\n",
    "    return SINE_TABLE, MAX_SINE, LOOKUP_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### direct component explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####explain idea of modulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### explanation about the c board"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The init function provides all the state variables and creates the SIN table.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# state variables\n",
    "def init(f_sine, samp_freq):\n",
    "    global sine_pointer\n",
    "    global x_prev\n",
    "    global GAIN\n",
    "    global SINE_TABLE\n",
    "    global MAX_SINE\n",
    "    global LOOKUP_SIZE\n",
    "\n",
    "    GAIN = 1\n",
    "    x_prev = 0\n",
    "    sine_pointer = 0\n",
    "    \n",
    "    # compute SINE TABLE\n",
    "    SINE_TABLE, MAX_SINE, LOOKUP_SIZE  = build_sine_table(f_sine, samp_freq, data_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The process function takes the input buffer (raw voice) and fills the output buffer with the pitch shiffted voice.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process(input_buffer, output_buffer, buffer_len):\n",
    "\n",
    "    # specify global variables modified here\n",
    "    global x_prev\n",
    "    global sine_pointer\n",
    "\n",
    "    for n in range(buffer_len):\n",
    "        \n",
    "        # high pass filter\n",
    "        output_buffer[n] = input_buffer[n] - x_prev\n",
    "\n",
    "        # modulation\n",
    "        output_buffer[n] = output_buffer[n] * SINE_TABLE[sine_pointer]/MAX_SINE\n",
    "\n",
    "        # update state variables\n",
    "        sine_pointer = (sine_pointer+1)%LOOKUP_SIZE\n",
    "        x_prev = input_buffer[n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can use this functions either in real-time or to process a wav file. Here is the main function for a wav file:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "You can tweak the following parameters to play with the function\n",
    "\"\"\"\n",
    "buffer_len = 256\n",
    "modulation_freq = 350\n",
    "input_wav = \"speech.wav\"\n",
    "\n",
    "\n",
    "samp_freq, signal = wavfile.read(input_wav)\n",
    "\n",
    "# If the wav file has several channels, just pick one of them\n",
    "if len(signal.shape)>1 :\n",
    "    signal = signal[:,0]\n",
    "    \n",
    "n_buffers = len(signal)//buffer_len\n",
    "data_type = signal.dtype\n",
    "\n",
    "# allocate input and output buffers\n",
    "input_buffer = np.zeros(buffer_len, dtype=data_type)\n",
    "output_buffer = np.zeros(buffer_len, dtype=data_type)\n",
    "\n",
    "\"\"\"\n",
    "Nothing to touch after this!\n",
    "\"\"\"\n",
    "\n",
    "init(modulation_freq, samp_freq)\n",
    "signal_proc = np.zeros(n_buffers*buffer_len, dtype=data_type)\n",
    "\n",
    "for k in range(n_buffers):\n",
    "\n",
    "    # index the appropriate samples\n",
    "    input_buffer = signal[k*buffer_len:(k+1)*buffer_len]\n",
    "    process(input_buffer, output_buffer, buffer_len)\n",
    "    signal_proc[k*buffer_len:(k+1)*buffer_len] = output_buffer\n",
    "\n",
    "# write to WAV\n",
    "wavfile.write(\"speech_mod.wav\", samp_freq, signal_proc)\n",
    "print(\"Done !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Right below is the code you can use to transform your own voice in real time.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################################################\n",
      "press Return to quit\n",
      "################################################################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "buffer_len = 256\n",
    "modulation_freq = 500\n",
    "data_type = np.int16\n",
    "samp_freq = 44100\n",
    "\n",
    "try:\n",
    "    sd.default.samplerate = 16000\n",
    "    sd.default.blocksize = buffer_len\n",
    "    sd.default.dtype = data_type\n",
    "\n",
    "    def callback(indata, outdata, frames, time, status):\n",
    "        if status:\n",
    "            print(status)\n",
    "        process(indata[:,0], outdata[:,0], frames)\n",
    "\n",
    "    init(modulation_freq, samp_freq)\n",
    "    with sd.Stream(channels=1, callback=callback):\n",
    "        print('#' * 80)\n",
    "        print('press Return to quit')\n",
    "        print('#' * 80)\n",
    "        input()\n",
    "except KeyboardInterrupt:\n",
    "    parser.exit('\\nInterrupted by user')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 3: GRANULAR SYNTHESIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main idea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this method, the pitch shifting is not achieved by an *explicit* modulation like the one used for the robot voice.\n",
    "\n",
    "\n",
    "Based on the input signal, the goal is to **create and use new samples at a higher rate with a technique that uses interpolation**.\n",
    "\n",
    "Concretely, those new samples will be separated by a period $T_s'$ that is smaller than the original period $T_s$.\n",
    "\n",
    "Let's take an example. Suppose the pitch factor is 0.75, ie you want to have a deeper voice.\n",
    "\n",
    "- The first block of data contains 10 samples at times $[0,1,2,3,4,5,6,7,8,9]$  $ ms$\n",
    "\n",
    "- The output contains the interpolated values of the input at times $0.75*[0,1,2,3,4,5,6,7,8,9]$  $ ms$\n",
    "    - Note 1: The interpolation is **linear**. So, $interpolatedValue(t=2.25)$ = $0.75*input(t=2) + 0.25*input(t=3)$ \n",
    "    - Note 2: The last interpolation time is $t = 9*0.75 = 6.75$. So there might be **losses of information**.\n",
    "    - Note 3: The 10 output samples will be played at the same rate $f_s$ than the input samples were recorded. In other words, it would initially take $6.75*f_s$ $ms$ to play the information embedded in the $[0,6.75]$ interval. In the output it would now take $9*f_s$  $ ms$ to play the same information.\n",
    "    \n",
    "    \n",
    "With this example, we can see that **the audio has been stretched by a factor 0.75**, making the output sound deeper than the original."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Because of the loss of information, there might be discontinuities between output blocks. **\n",
    "\n",
    "\n",
    "This is an annoying artifact since discontinuities in an audio file result in \"tick\" noises that alter the overall audio quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution : use overlapping grains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trick is to use overlapping blocks of samples that are called 'grains'. Be careful : here, overlapping does not mean that output samples are a mix between consecutive input blocks.Instead, it means that **some samples will be processed twice in row.**\n",
    "\n",
    "- The first time as the last samples of a grain\n",
    "- The second time as the first samples of the next grain\n",
    "\n",
    "As in the previous example, **interpolated values are computed for each grain at times $grainStart + k*shiftFactor*T_s$  ** with $T_s$ the sampling period and $k$ an integer number ranging from 0 to the number of samples in the grain.\n",
    "\n",
    "**Important :** Where two grains overlap, two \"families\" of interpolated values are compute (ie one for each grain). In order to avoid discontinuities between them, it is necessary to use a tappering window on those overlapping zones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method uses chunks of data called \"grains\". The pitch shifting is not achieved by an explicit modulation as in the previous case but with upsampling. The upsampled signal is obtained from the raw input using linear interpolation.\n",
    "\n",
    "- expliquer que les temps d'interpolations restent les mêmes (premiere look up table samp_vals)\n",
    "- expliquer la deuxieme look up table (amp_vals) coefficients multiplicateurs\n",
    "- IMAGE\n",
    "\n",
    "- expliquer comment fonctionne les grains (ce qu'ils contiennent) et que l'on ne peut pas simplement process grain par grain\n",
    "- IMAGES\n",
    "\n",
    "- besoind d'utiliser une window (pq cette window)\n",
    "- expliquer la zone d overlap qui se fait sur les memes samples mais a des temps d'interpolation differents. On applique la down window sur la fin du premier grain et la up window sur le debut de second pour faire un transition smooth entre les grains. Les windows s appliquent sur les valeur interpolées \n",
    "- image\n",
    "\n",
    "- expliquer les buffers que l'on utilise.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Anaconda3]",
   "language": "python",
   "name": "Python [Anaconda3]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
