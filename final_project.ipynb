{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REAL TIME PITCH SHIFTING "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 1: INTRODUCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This notebook presents several techniques to perform pitch shifting in real time.\n",
    "Concretely, the goal is to transform in real time the voice of a person by making it deeper.**\n",
    "\n",
    "**In particular this notebook will explore the robot voice technique, the basic granular synthesis algorithm and finally a more advanced version of the latter that uses LPC.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Of course, it is obviously impossible to achieve pure real time (ie bit per bit) processing. The data will be processed using buffers of the smallest size as possible.**\n",
    "\n",
    "So, the main problem induced by the real time approach is that the processing has to be very efficient so that there is no big delay between input and output signals. To face this constraint there are a few things that must be done:\n",
    "    1. using integers value as much as possible.\n",
    "    2. using precomputed look-up-table (LUT) to avoid useless repetive computations.\n",
    "    3. coding as in C (close to the machine)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need the following libraries to handle all the audio processing to come:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "\n",
    "import numpy as np\n",
    "import sounddevice as sd\n",
    "from scipy.io import wavfile\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.signal as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 2: ROBOT VOICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, the robot voice implementation is given in python, allowing you to use it here. But you can also find a talk about a C implementation of the process. This is useful if you want to use the robot voice on a board with real microphones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a SIN table ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In order to implement the robot voice effect, we only need to multiply the input signals with a sinusoid. However, in real time computing, the sine of a given value cannot be processed by most computers and microcontrollers. Therefore, we use a lookup table to precompute the unique samples of the sinusoid signal before the computation. Then, during the process, we recall the samples from the memory as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The following function precomputes the SIN table in python**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define necessary utility functions\n",
    "def build_sine_table(f_sine, samp_freq, data_type):\n",
    "    \n",
    "    \n",
    "    # compute the integer conversion parameters\n",
    "    if data_type == np.int16:\n",
    "        MAX_SINE = 2**(15)-1\n",
    "    elif data_type == np.int32:\n",
    "        MAX_SINE = 2**(31)-1\n",
    "    \n",
    "    # periods\n",
    "    samp_per = 1./samp_freq\n",
    "    sine_per = 1./f_sine\n",
    "\n",
    "    # compute the right number of (integer) time instances\n",
    "    LOOKUP_SIZE = len(np.arange(0, sine_per, samp_per))\n",
    "    n = np.arange(LOOKUP_SIZE)\n",
    "    \n",
    "    \n",
    "    freq_step = f_sine/samp_freq\n",
    "    SINE_TABLE = np.sin(2*np.pi*n*freq_step) * MAX_SINE\n",
    "\n",
    "    return SINE_TABLE, MAX_SINE, LOOKUP_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The following function precomputes the SIN table in C**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "const int16_t SINE_TABLE[sine_table_size] = {\n",
    "0x0000,0x0a0a,0x1405,0x1de1,0x278d,0x30fb,0x3a1b,0x42e0,\n",
    "0x4b3b,0x5320,0x5a81,0x6154,0x678d,0x6d22,0x720b,0x7640,\n",
    "0x79bb,0x7c75,0x7e6b,0x7f99,0x7fff,0x7f99,0x7e6b,0x7c75,\n",
    "0x79bb,0x7640,0x720b,0x6d22,0x678d,0x6154,0x5a81,0x5320,\n",
    "0x4b3b,0x42e0,0x3a1b,0x30fb,0x278d,0x1de1,0x1405,0x0a0a,\n",
    "0x0000,0xf5f6,0xebfb,0xe21f,0xd873,0xcf05,0xc5e5,0xbd20,\n",
    "0xb4c5,0xace0,0xa57f,0x9eac,0x9873,0x92de,0x8df5,0x89c0,\n",
    "0x8645,0x838b,0x8195,0x8067,0x8001,0x8067,0x8195,0x838b,\n",
    "0x8645,0x89c0,0x8df5,0x92de,0x9873,0x9eac,0xa57f,0xace0,\n",
    "0xb4c5,0xbd20,0xc5e5,0xcf05,0xd873,0xe21f,0xebfb,0xf5f6\n",
    "};"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation of the process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you can see how the ouput is processed such that a robot kind of voice is obtained.\n",
    "\n",
    "If you ask yourself why the output_buffer is the one being multiplied by the SIN table and not the input_buffer, then you will find your answer in the next part which is talking about DC noise removal."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "output_buffer[n] = output_buffer[n] * SINE_TABLE[sine_pointer]/MAX_SINE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. sine_pointer is used as the index of the SINE_TABLE.\n",
    "2. MAX_SINE is the maximum value of SINE_TABLE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Integer type variables are used in order to save processing time. But since the sine window has a range that spans the interval [0,1], this is suitable to use float steps such as 0.1,0.2, etc...\n",
    "\n",
    "Therefore, in order to maximize the precision and minimize at the same time the computation cost, the full range of the int16 (i.e 65535 values in this case) is used. Thus the SINE_TABLE is first multiplied by MAX_SINE in the builder. Then, during the modulation, the SIN_TABLE is divided by MAX_SINE to perform integer arithmetic without losing precision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DC noise removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the audio capture, the internal circuitry in the microphone may add an offset.Also sometimes different microphones will have different offsets which could be really problematic. \n",
    "\n",
    "this shift is typically called the waveform DC noise. For the robot voice effect, a DC noise would result in a constant sinusoid present in the output signal. For you to understand it, below is the real signal you are working on:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "x'[n] = (x[n] + n_DC) \n",
    "\n",
    "# so you obtain via processing:\n",
    "x'[n] * sin (w_mod * n) \n",
    "= (x[n] + n_DC) * sin (w_mod * n) \n",
    "= y[n] + n_DC * sin (w_mod * n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where y[n] are the samples of our desired robot voice effect and n_DC is the level of the DC noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To remove the DC noise (that we suppose constant over time) a simple high pass filter is implemented. This filter will remove any DC component of the signal, i.e. bin number 0 of the Discrete Fourier Transform(DFT). A cheap high pass filter of the following form is used to stay efficient:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "y[n] = x[n] - x[n-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A problem of this approach is that even though the DC noise is removed, the filter also attenuate frequencies in the range of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmarking (in C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Benchmarking is implemented using a timer to measure real-time processing speed.\n",
    "\n",
    "Timers always have an input clock with one of the timebases of the microcontroller internal clocks (a quartz for example). This timebase can be either taken directly or reduced by a factor called a [prescaler](https://en.wikipedia.org/wiki/Prescaler). It is important to chose an appropriate prescaler value as it will define how fast the timer counts. For this application, the prescaler value is set as 48 to achieve a 1[μs] period for the Internal Clock i.e. the timer must have a 1[μs] resolution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this C implementation, the processing time is around 1800[μs] which is 10% of the buffer time (16000[μs])."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hardware (in C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the hardware a STM32 Nucleo-64 development board is used with the STM32F072RB microcontroller unit and the I2S MEMS Microphone Breakout by Adafruit. For the DAC (Digital-to-Analog Converter), a Adafruit's I2S Stereo Decoder Breakout is used, which contains the DAC, an audio jack for connecting headphones, and the necessary additional components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you can find the python implementation of the robot voice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The init function provides all the state variables and creates the SIN table.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state variables\n",
    "def init(f_sine, samp_freq):\n",
    "    global sine_pointer\n",
    "    global x_prev\n",
    "    global GAIN\n",
    "    global SINE_TABLE\n",
    "    global MAX_SINE\n",
    "    global LOOKUP_SIZE\n",
    "\n",
    "    GAIN = 1\n",
    "    x_prev = 0\n",
    "    sine_pointer = 0\n",
    "    \n",
    "    # compute SINE TABLE\n",
    "    SINE_TABLE, MAX_SINE, LOOKUP_SIZE  = build_sine_table(f_sine, samp_freq, data_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The process function takes the input buffer (raw voice) and fills the output buffer with the pitch shiffted voice.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(input_buffer, output_buffer, buffer_len):\n",
    "\n",
    "    # specify global variables modified here\n",
    "    global x_prev\n",
    "    global sine_pointer\n",
    "\n",
    "    for n in range(buffer_len):\n",
    "        \n",
    "        # high pass filter\n",
    "        output_buffer[n] = input_buffer[n] - x_prev\n",
    "\n",
    "        # modulation\n",
    "        output_buffer[n] = output_buffer[n] * SINE_TABLE[sine_pointer]/MAX_SINE\n",
    "\n",
    "        # update state variables\n",
    "        sine_pointer = (sine_pointer+1)%LOOKUP_SIZE\n",
    "        x_prev = input_buffer[n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can use this functions either in real-time or to process a wav file. Here is the main function for a wav file:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\prog_python_scala\\python\\lib\\site-packages\\scipy\\io\\wavfile.py:273: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  WavFileWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done !\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "You can tweak the following parameters to play with the function\n",
    "\"\"\"\n",
    "buffer_len = 256\n",
    "modulation_freq = 350\n",
    "input_wav = \"speech.wav\"\n",
    "\n",
    "\n",
    "samp_freq, signal = wavfile.read(input_wav)\n",
    "\n",
    "# If the wav file has several channels, just pick one of them\n",
    "if len(signal.shape)>1 :\n",
    "    signal = signal[:,0]\n",
    "    \n",
    "n_buffers = len(signal)//buffer_len\n",
    "data_type = signal.dtype\n",
    "\n",
    "# allocate input and output buffers\n",
    "input_buffer = np.zeros(buffer_len, dtype=data_type)\n",
    "output_buffer = np.zeros(buffer_len, dtype=data_type)\n",
    "\n",
    "\"\"\"\n",
    "Nothing to touch after this!\n",
    "\"\"\"\n",
    "\n",
    "init(modulation_freq, samp_freq)\n",
    "signal_proc = np.zeros(n_buffers*buffer_len, dtype=data_type)\n",
    "\n",
    "for k in range(n_buffers):\n",
    "\n",
    "    # index the appropriate samples\n",
    "    input_buffer = signal[k*buffer_len:(k+1)*buffer_len]\n",
    "    process(input_buffer, output_buffer, buffer_len)\n",
    "    signal_proc[k*buffer_len:(k+1)*buffer_len] = output_buffer\n",
    "\n",
    "# write to WAV\n",
    "wavfile.write(\"speech_mod.wav\", samp_freq, signal_proc)\n",
    "print(\"Done !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Right below is the code you can use to transform your own voice in real time.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################################################\n",
      "press Return to quit\n",
      "################################################################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "buffer_len = 256\n",
    "modulation_freq = 500\n",
    "data_type = np.int16\n",
    "samp_freq = 44100\n",
    "\n",
    "try:\n",
    "    sd.default.samplerate = 16000\n",
    "    sd.default.blocksize = buffer_len\n",
    "    sd.default.dtype = data_type\n",
    "\n",
    "    def callback(indata, outdata, frames, time, status):\n",
    "        if status:\n",
    "            print(status)\n",
    "        process(indata[:,0], outdata[:,0], frames)\n",
    "\n",
    "    init(modulation_freq, samp_freq)\n",
    "    with sd.Stream(channels=1, callback=callback):\n",
    "        print('#' * 80)\n",
    "        print('press Return to quit')\n",
    "        print('#' * 80)\n",
    "        input()\n",
    "except KeyboardInterrupt:\n",
    "    parser.exit('\\nInterrupted by user')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 3: GRANULAR SYNTHESIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main idea : the resampling technique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this method, the pitch shifting is not achieved by an *explicit* modulation like the one used for the robot voice.\n",
    "\n",
    "\n",
    "Based on the input signal, the goal is to **create and use new samples at a higher rate through interpolation**.\n",
    "\n",
    "Concretely, those new samples will be separated by a period $T_s'$ that is smaller than the original period $T_s$.\n",
    "\n",
    "Let's take an example. Suppose the pitch factor is 0.75, ie you want to have a deeper voice.\n",
    "\n",
    "- The first block of data contains 10 samples at times $[0,1,2,3,4,5,6,7,8,9]$  $ ms$\n",
    "\n",
    "- The output will contain interpolated values of the input at times $0.75 \\times [0,1,2,3,4,5,6,7,8,9]$  $ ms$\n",
    "\n",
    "**We must note 3 things here**:\n",
    "\n",
    "\n",
    "- Note 1: The interpolation is **linear**. So, $interpolatedValue(t=2.25)$ = $0.75 \\times input(t=2) + 0.25 \\times input(t=3)$ \n",
    "\n",
    "\n",
    "- Note 2: The last interpolation time is $t = 9 \\times 0.75 = 6.75$. So there might be **losses of information** (raw samples at times $t = [8,9]$).\n",
    "\n",
    "\n",
    "- Note 3: The 10 output samples will be played at the **same rate $f_s$** than the one of the 10 input samples.\n",
    "\n",
    "$\\to$ It took initially $6.75$ $ms$ to record the information embedded in the $[0,6.75]$ interval. But after the transformation, it takes $9$  $ ms$ to play the same (resampled) information.\n",
    "    \n",
    "    \n",
    "$\\to$ **the audio has been _stretched_ by a factor 0.75**, making the output sound deeper than the original."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Because of the loss of information, there might be discontinuities between output blocks.**\n",
    "\n",
    "\n",
    "This is an annoying artifact since discontinuities in an audio file result in \"tick\" noises that alter the overall audio quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution : use overlapping grains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trick is to use overlapping chunks of samples that are called $grains$. \n",
    "\n",
    "Be careful : here, overlapping does not mean that output samples are a mix between consecutive input blocks.\n",
    "\n",
    "Instead, it means that **some raw samples will be processed twice in row.**\n",
    "\n",
    "- The first time as the last samples of a grain\n",
    "- The second time as the first samples of the next grain\n",
    "\n",
    "---------\n",
    "As a general rule (and as in the previous example), interpolated values are computed for each grain at times $grainStart + k \\times shiftFactor \\times T_s$ \n",
    "\n",
    "- $T_s$ the sampling period\n",
    "- $k$ an integer number ranging from 0 to the number of samples in the grain.\n",
    "\n",
    "\n",
    "--------------------------\n",
    "\n",
    "\n",
    "**Important :** \n",
    "\n",
    "For samples belonging to $2$ consecutive grains, $2$ different interpolated values are computed (ie one for each grain). Hence, it is necessary to find a way of **combining those two values** so that there is not brutal discontinuity between output samples. This is achieved by using a **tapered window**.\n",
    "\n",
    "A tapered window is simply an array that associates a multiplicative factor to each resampled (ie interpolated) value.\n",
    "- For zones with no overlap, this factor is simply 1\n",
    "- For zones with overlap, this factor is a number in $[0,1]$ that follows a linear function\n",
    "    - This function is increasing for reampled values at the start of a grain\n",
    "    - This function is decreasing for resampled values at the end of a grain\n",
    "\n",
    "\n",
    "**Concretely :**\n",
    "When there are two different resampled values for the same output sample:\n",
    "- $resampled\\_value_1$ is scaled by the tapered window of its grain evaluated at time $t=output\\_sample\\_time$\n",
    "- $resampled\\_value_2$ is scaled by the tapered window of its grain evaluated at time $t=output\\_sample\\_time$\n",
    "- output sample = $scaled\\_resampled\\_value_1$ + $scaled\\_resampled\\_value_2$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "As an image is worth a thousand words, let's have a look at the following example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://i.postimg.cc/ZqLH95hQ/resampling-times.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://i.postimg.cc/ZqLH95hQ/resampling-times.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the figure above, each square represents 1 time unit ($TU$).\n",
    "\n",
    "- The input samples are represented in dark blue. We can see that $T_s=6$  $TU$\n",
    "- The pitch shifting factor is $\\frac{11}{12}$ so this implies that $T_s'=5.5$ $TU$\n",
    "\n",
    "For both grains, we can see that resampling times (pink and light blue ticks on the x-axis) are placed at integer multiples of $T_s'$ from the start of the grains.\n",
    "\n",
    "We can see that the **raw** samples at times $t=[36, 42, 48, 54]$ $TU$ belong to two different grains and will thus be processed twice.\n",
    "- The first time to compute $sample_{pink}(t= [38.5, 44, 49.5])$\n",
    "- The second time to compute $sample_{blue}(t= [41.5, 47, 52.5])$\n",
    "--------------\n",
    "**Note** :\n",
    "- Here we only show the first two grains of the audio stream, so the first samples of $grain_1$ are exclusively used for $grain_1$ (since there is no $grain_0$ !)\n",
    "- With the same idea, the last samples of the last grain of the audio stream will also be used exclusively for this last grain.\n",
    "\n",
    "-------------\n",
    "\n",
    "On the figure below, you can see all the resampled (interpolated) values computed for every resample time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://i.postimg.cc/KYbQvgCL/resampled-values.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"https://i.postimg.cc/KYbQvgCL/resampled-values.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last thing to do in this example is to scale and merge the interpolated values of $grain_1$ and $grain_2$ that overlap.\n",
    "\n",
    "**Concretely** :\n",
    "- $sample_{pink}(t=38.5)$ and $sample_{blue}(t=41.5)$ must be merged to compute $sample_{output}(t=42)$\n",
    "\n",
    "\n",
    "- As $window_{pink}(t=42) = \\frac{2}{3}$ and $window_{blue}(t=42) = \\frac{1}{3}$\n",
    "\n",
    "\n",
    "- $sample_{output}(t=42)$ =  $window_{pink}(t=42) \\times sample_{pink}(t=38.5) + window_{blue}(t=42) \\times sample_{blue}(t=41.5)$\n",
    "\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$= \\frac{2}{3} \\times sample_{pink}(t=38.5) + \\frac{1}{3} \\times sample_{blue}(t=41.5)$ \n",
    "\n",
    "\n",
    "--------------------\n",
    "**Important Note : do not forget that the samples blocks arrive one after the other ! This implies that :** \n",
    "- In order to compute the output samples corresponding to the last raw samples of the grain, it is necessary to wait for the next sample block. When the latter arrives, the second grain can be formed and the output sample can finally be computed, as all the overlapping samples (ex : pink **and** light blue) are available.\n",
    "\n",
    "\n",
    "- Each newly arrived sample bloc needs to have access to:\n",
    "    1. The last **raw** samples of the preceding block $\\to$ build the new grain\n",
    "    2. The last resampled values (pink) of the preceding block $\\to$ compute the output samples for the overlapping part at the start of this new grain.\n",
    "    \n",
    "    \n",
    "**In our example **: Everytime a block arrives, only $6$ output samples can be directly computed. The remaining $3$ resampling values (at the end of the block) need to be combined with the first $3$ resampling values that will be computed in the next grain.\n",
    "\n",
    "${\\to}$ This value $6$ is refered to as the $stride$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From theory to implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now that the algorithm has been explained, it is time to understand the implications of every constraint in the implementation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Constant parameters\n",
    "\n",
    "- Number of samples in a grain $\\to$ $GRAIN\\_LEN\\_SAMP$\n",
    "- Number of output samples that can be produced without the need of the next grain $\\to$ $STRIDE$\n",
    "- The tapering window of length $GRAIN\\_LEN\\_SAMP$ $\\to$ $WIN$\n",
    "    - In fact the length of the mixing edges of the window can be modified (it will obviously modify $STRIDE$ value )\n",
    "\n",
    "Interpolation :\n",
    "- Resampling times with respect to the start of the grain (pink and light-blue time indices) $\\to$ $SAMP\\_VALS$\n",
    "- The amplitude factor associated to the preceding raw sample for each resampling time $\\to$ $AMP\\_VALS$ (necessary to perform linear interpolation)\n",
    "    - In this example : $interpolatedValue(t=2.25)$ = $0.75 \\times input(t=2)+0.25 \\times input(t=3)$,&nbsp;&nbsp;  $AMP\\_VALS(t=2.25) = 0.75$\n",
    "\n",
    "\n",
    "    \n",
    "###### What arrives at each iteration\n",
    "- A sample block of &nbsp;$STRIDE$&nbsp; samples\n",
    "\n",
    "\n",
    "###### To be passed between each sample blocks\n",
    "- The last raw samples of the previous block $\\to$ $PREVIOUS\\_RAW$\n",
    "    - Note : those samples concatenated with the &nbsp;$STRIDE$ samples of the arriving block makes a full grain\n",
    "    \n",
    "    \n",
    "- The last fully processed resampled values (window scaling included) of the previous block $\\to$ $PREVIOUS\\_DOWN\\_WINDOWED$ \n",
    "\n",
    "###### Locally used variables\n",
    "\n",
    "- The grain formed by the incoming raw sample block concatenated with the $PREVIOUS\\_RAW$ samples $\\to$ $GRAIN$\n",
    "- The array containing the resampled values and then the window-scaled resampled values $\\to$ $RESAMPLED\\_GRAIN$"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
