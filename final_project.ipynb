{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REAL TIME PITCH SHIFTING "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 1: INTRODUCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This notebook presents several techniques to perform pitch shifting in real time.\n",
    "Concretely, the goal is to transform in real time the voice of a person by making it deeper.**\n",
    "\n",
    "**In particular this notebook will explore the robot voice technique, the basic granular synthesis algorithm and finally a more advanced version of the latter that uses LPC.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Of course, it is obviously impossible to achieve pure real time (ie bit per bit) processing. The data will be processed using buffers of the smallest size as possible.**\n",
    "\n",
    "So, the main problem induced by the real time approach is that the processing has to be very efficient so that there is no big delay between input and output signals. To face this constraint there are a few things that must be done:\n",
    "    1. using integers value as much as possible.\n",
    "    2. using precomputed look-up-table (LUT) to avoid useless repetive computations.\n",
    "    3. coding as in C (close to the machine)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need the following libraries to handle all the audio processing to come:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "\n",
    "import numpy as np\n",
    "import sounddevice as sd\n",
    "from scipy.io import wavfile\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.signal as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 2: ROBOT VOICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a SIN table ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### text about sin table, explain why this is a constant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function precomputes the SIN table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define necessary utility functions\n",
    "def build_sine_table(f_sine, samp_freq, data_type):\n",
    "    \n",
    "    \n",
    "    # compute the integer conversion parameters\n",
    "    if data_type == np.int16:\n",
    "        MAX_SINE = 2**(15)-1\n",
    "    elif data_type == np.int32:\n",
    "        MAX_SINE = 2**(31)-1\n",
    "    \n",
    "    # periods\n",
    "    samp_per = 1./samp_freq\n",
    "    sine_per = 1./f_sine\n",
    "\n",
    "    # compute the right number of (integer) time instances\n",
    "    LOOKUP_SIZE = len(np.arange(0, sine_per, samp_per))\n",
    "    n = np.arange(LOOKUP_SIZE)\n",
    "    \n",
    "    \n",
    "    freq_step = f_sine/samp_freq\n",
    "    SINE_TABLE = np.sin(2*np.pi*n*freq_step) * MAX_SINE\n",
    "\n",
    "    return SINE_TABLE, MAX_SINE, LOOKUP_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### direct component explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####explain idea of modulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### explanation about the c board"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The init function provides all the state variables and creates the SIN table.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# state variables\n",
    "def init(f_sine, samp_freq):\n",
    "    global sine_pointer\n",
    "    global x_prev\n",
    "    global GAIN\n",
    "    global SINE_TABLE\n",
    "    global MAX_SINE\n",
    "    global LOOKUP_SIZE\n",
    "\n",
    "    GAIN = 1\n",
    "    x_prev = 0\n",
    "    sine_pointer = 0\n",
    "    \n",
    "    # compute SINE TABLE\n",
    "    SINE_TABLE, MAX_SINE, LOOKUP_SIZE  = build_sine_table(f_sine, samp_freq, data_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The process function takes the input buffer (raw voice) and fills the output buffer with the pitch shiffted voice.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process(input_buffer, output_buffer, buffer_len):\n",
    "\n",
    "    # specify global variables modified here\n",
    "    global x_prev\n",
    "    global sine_pointer\n",
    "\n",
    "    for n in range(buffer_len):\n",
    "        \n",
    "        # high pass filter\n",
    "        output_buffer[n] = input_buffer[n] - x_prev\n",
    "\n",
    "        # modulation\n",
    "        output_buffer[n] = output_buffer[n] * SINE_TABLE[sine_pointer]/MAX_SINE\n",
    "\n",
    "        # update state variables\n",
    "        sine_pointer = (sine_pointer+1)%LOOKUP_SIZE\n",
    "        x_prev = input_buffer[n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can use this functions either in real-time or to process a wav file. Here is the main function for a wav file:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "You can tweak the following parameters to play with the function\n",
    "\"\"\"\n",
    "buffer_len = 256\n",
    "modulation_freq = 350\n",
    "input_wav = \"speech.wav\"\n",
    "\n",
    "\n",
    "samp_freq, signal = wavfile.read(input_wav)\n",
    "\n",
    "# If the wav file has several channels, just pick one of them\n",
    "if len(signal.shape)>1 :\n",
    "    signal = signal[:,0]\n",
    "    \n",
    "n_buffers = len(signal)//buffer_len\n",
    "data_type = signal.dtype\n",
    "\n",
    "# allocate input and output buffers\n",
    "input_buffer = np.zeros(buffer_len, dtype=data_type)\n",
    "output_buffer = np.zeros(buffer_len, dtype=data_type)\n",
    "\n",
    "\"\"\"\n",
    "Nothing to touch after this!\n",
    "\"\"\"\n",
    "\n",
    "init(modulation_freq, samp_freq)\n",
    "signal_proc = np.zeros(n_buffers*buffer_len, dtype=data_type)\n",
    "\n",
    "for k in range(n_buffers):\n",
    "\n",
    "    # index the appropriate samples\n",
    "    input_buffer = signal[k*buffer_len:(k+1)*buffer_len]\n",
    "    process(input_buffer, output_buffer, buffer_len)\n",
    "    signal_proc[k*buffer_len:(k+1)*buffer_len] = output_buffer\n",
    "\n",
    "# write to WAV\n",
    "wavfile.write(\"speech_mod.wav\", samp_freq, signal_proc)\n",
    "print(\"Done !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Right below is the code you can use to transform your own voice in real time.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################################################\n",
      "press Return to quit\n",
      "################################################################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "buffer_len = 256\n",
    "modulation_freq = 500\n",
    "data_type = np.int16\n",
    "samp_freq = 44100\n",
    "\n",
    "try:\n",
    "    sd.default.samplerate = 16000\n",
    "    sd.default.blocksize = buffer_len\n",
    "    sd.default.dtype = data_type\n",
    "\n",
    "    def callback(indata, outdata, frames, time, status):\n",
    "        if status:\n",
    "            print(status)\n",
    "        process(indata[:,0], outdata[:,0], frames)\n",
    "\n",
    "    init(modulation_freq, samp_freq)\n",
    "    with sd.Stream(channels=1, callback=callback):\n",
    "        print('#' * 80)\n",
    "        print('press Return to quit')\n",
    "        print('#' * 80)\n",
    "        input()\n",
    "except KeyboardInterrupt:\n",
    "    parser.exit('\\nInterrupted by user')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 3: GRANULAR SYNTHESIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main idea : the resampling technique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this method, the pitch shifting is not achieved by an *explicit* modulation like the one used for the robot voice.\n",
    "\n",
    "\n",
    "Based on the input signal, the goal is to **create and use new samples at a higher rate through interpolation**.\n",
    "\n",
    "Concretely, those new samples will be separated by a period $T_s'$ that is smaller than the original period $T_s$.\n",
    "\n",
    "Let's take an example. Suppose the pitch factor is 0.75, ie you want to have a deeper voice.\n",
    "\n",
    "- The first block of data contains 10 samples at times $[0,1,2,3,4,5,6,7,8,9]$  $ ms$\n",
    "\n",
    "- The output will contain interpolated values of the input at times $0.75 \\times [0,1,2,3,4,5,6,7,8,9]$  $ ms$\n",
    "    - Note 1: The interpolation is **linear**. So, $interpolatedValue(t=2.25)$ = $0.75 \\times input(t=2) + 0.25*input(t=3)$ \n",
    "    - Note 2: The last interpolation time is $t = 9 \\times 0.75 = 6.75$. So there might be **losses of information**.\n",
    "    - Note 3: The 10 output samples will be played at the same rate $f_s$ than the input samples were recorded. In other words, it would initially take $6.75 \\times f_s$ $ms$ to play the information embedded in the $[0,6.75]$ interval. In the output, it takes now $9 \\times f_s$  $ ms$ to play the same information.\n",
    "    \n",
    "    \n",
    "With this example, we can see that **the audio has been _stretched_ by a factor 0.75**, making the output sound deeper than the original."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Because of the loss of information, there might be discontinuities between output blocks. **\n",
    "\n",
    "\n",
    "This is an annoying artifact since discontinuities in an audio file result in \"tick\" noises that alter the overall audio quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution : use overlapping grains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trick is to use overlapping blocks of samples that are called 'grains'. \n",
    "\n",
    "Be careful : here, overlapping does not mean that output samples are a mix between consecutive input blocks.Instead, it means that **some samples will be processed twice in row.**\n",
    "\n",
    "- The first time as the last samples of a grain\n",
    "- The second time as the first samples of the next grain\n",
    "\n",
    "As in the previous example, **interpolated values are computed for each grain at times $grainStart + k*shiftFactor*T_s$ \n",
    "\n",
    "- $T_s$ the sampling period\n",
    "- $k$ an integer number ranging from 0 to the number of samples in the grain.\n",
    "\n",
    "\n",
    "--------------------------\n",
    "\n",
    "\n",
    "**Important :** Where two grains overlap, two \"families\" of interpolated values are computed (ie one for each grain). In other words, there will be two different interpolated values for the same output value. Hence, it is necessary to find a way of combining those two values so that there is not brutal discontinuity between output samples. This is achieved by using a **tapering window** on those overlapping zones.\n",
    "\n",
    "A tapering window is simply a vector that associates a multiplicative factor to each resampled (ie interpolated) value.\n",
    "- For zones with no overlap, this factor is simply 1\n",
    "- For zones with overlap, this factor is a number in $[0,1]$ that follows a linear function\n",
    "    - This function is increasing for reampled values at the start of a grain\n",
    "    - This function is decreasing for resampled values at the end of a grain\n",
    "\n",
    "\n",
    "**Concretely :**\n",
    "When there are two different resampled values for the same output sample:\n",
    "- resampled value no 1 is scaled by the tapering window of its grain evaluated at time $t=output\\_sample\\_time$\n",
    "- resampled value no 2 is scaled by the tapering window of its grain evaluated at time $t=output\\_sample\\_time$\n",
    "- output sample = $scaled\\_resampled\\_value_1$ + $scaled\\_resampled\\_value_2$\n",
    "\n",
    "So, if there are two different resampled values for the same output sample, those values are scaled by the tapering window corresponding to their respective grain and the output sample is simply the sum of those scaled values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "As an image is worth a thousand words, let's have a look at the following example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://i.postimg.cc/ZqLH95hQ/resampling-times.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://i.postimg.cc/ZqLH95hQ/resampling-times.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the figure above, each square represents 1 time unit ($TU$).\n",
    "\n",
    "- The input samples are represented in dark blue. We can see that $T_s=6$  $TU$\n",
    "- The pitch shifting factor is $\\frac{11}{12}$ so this implies that $T_s'=5.5$ $TU$\n",
    "\n",
    "For both grains, we can see that resampling times (pink and light blue ticks on the x-axis) are placed at integer multiples of $T_s'$ from the start of the grains.\n",
    "\n",
    "We can see that the raw samples at times $t=[36, 42, 48, 54]$ $TU$ belong to two different grains and will thus be processed twice.\n",
    "- The first time to compute $sample_{pink}(t= [38.5, 44, 49.5])$\n",
    "- The second time to compute $sample_{blue}(t= [41.5, 47, 52.5])$\n",
    "\n",
    "**Note** :\n",
    "- Here we only show the first two grains of the audio stream, so the first samples of grain1 are exclusively used for $grain_1$ (since there is no $grain_0$ !)\n",
    "- With the same idea, the last samples of the last grain of the audio stream will also be used exclusively for this last grain\n",
    "\n",
    "-------------\n",
    "\n",
    "On the figure below, you can see all the resampled (interpolated) values computed for every resample time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://i.postimg.cc/KYbQvgCL/resampled-values.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"https://i.postimg.cc/KYbQvgCL/resampled-values.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last thing to do in this example is to scale and merge the interpolated values of $grain_1$ and $grain_2$ that overlap. **Concretely** :\n",
    "- $sample_{pink}(t=38.5)$ and $sample_{blue}(t=41.5)$ must be merged to compute $sample_{output}(t=42)$\n",
    "\n",
    "\n",
    "- As $window_{pink}(t=42) = \\frac{2}{3}$ and $window_{blue}(t=42) = \\frac{1}{3}$\n",
    "\n",
    "\n",
    "- $sample_{output}(t=42)$ =  $window_{pink}(t=42) \\times sample_{pink}(t=38.5) + window_{blue}(t=42) \\times sample_{blue}(t=41.5)$\n",
    "\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$= \\frac{2}{3} \\times sample_{pink}(t=38.5) + \\frac{1}{3} \\times sample_{blue}(t=41.5)$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From theory to implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now that the algorithm has been explained, it is time to understand the implications of every constraint in the implementation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Constant parameters**\n",
    "- Number of samples in a grain $\\to$ GRAIN_LEN_SAMP\n",
    "- Resampling times with respect to the start of the grain $\\to$ SAMP_VALS\n",
    "- The amplitude associated to the preceding raw sample for each resampling time $\\to$ AMP_VALS (necessary to perform linear interpolation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method uses chunks of data called \"grains\". The pitch shifting is not achieved by an explicit modulation as in the previous case but with upsampling. The upsampled signal is obtained from the raw input using linear interpolation.\n",
    "\n",
    "- expliquer que les temps d'interpolations restent les mêmes (premiere look up table samp_vals)\n",
    "- expliquer la deuxieme look up table (amp_vals) coefficients multiplicateurs\n",
    "- IMAGE\n",
    "\n",
    "- expliquer comment fonctionne les grains (ce qu'ils contiennent) et que l'on ne peut pas simplement process grain par grain\n",
    "- IMAGES\n",
    "\n",
    "- besoind d'utiliser une window (pq cette window)\n",
    "- expliquer la zone d overlap qui se fait sur les memes samples mais a des temps d'interpolation differents. On applique la down window sur la fin du premier grain et la up window sur le debut de second pour faire un transition smooth entre les grains. Les windows s appliquent sur les valeur interpolées \n",
    "- image\n",
    "\n",
    "- expliquer les buffers que l'on utilise.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Anaconda3]",
   "language": "python",
   "name": "Python [Anaconda3]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
