{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REAL TIME PITCH SHIFTING "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 1: INTRODUCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This notebook presents several techniques to perform pitch shifting in real time.\n",
    "Concretely, the goal is to transform in real time the voice of a person by making it deeper.**\n",
    "\n",
    "**In particular this notebook will explore the robot voice technique, the basic granular synthesis algorithm and finally a more advanced version of the latter that uses LPC.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Of course, it is obviously impossible to achieve pure real time (ie bit per bit) processing. The data will be processed using buffers of the smallest size as possible.**\n",
    "\n",
    "So, the main problem induced by the real time approach is that the processing has to be very efficient so that there is no big delay between input and output signals. To face this constraint there are a few things that must be done:\n",
    "    1. using integers value as much as possible.\n",
    "    2. using precomputed look-up-table (LUT) to avoid useless repetive computations.\n",
    "    3. coding as in C (close to the machine)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need the following libraries to handle all the audio processing to come:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "\n",
    "import numpy as np\n",
    "import sounddevice as sd\n",
    "from scipy.io import wavfile\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.signal as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 2: ROBOT VOICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a SIN table ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### text about sin table, explain why this is a constant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function precomputes the SIN table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define necessary utility functions\n",
    "def build_sine_table(f_sine, samp_freq, data_type):\n",
    "    \n",
    "    \n",
    "    # compute the integer conversion parameters\n",
    "    if data_type == np.int16:\n",
    "        MAX_SINE = 2**(15)-1\n",
    "    elif data_type == np.int32:\n",
    "        MAX_SINE = 2**(31)-1\n",
    "    \n",
    "    # periods\n",
    "    samp_per = 1./samp_freq\n",
    "    sine_per = 1./f_sine\n",
    "\n",
    "    # compute the right number of (integer) time instances\n",
    "    LOOKUP_SIZE = len(np.arange(0, sine_per, samp_per))\n",
    "    n = np.arange(LOOKUP_SIZE)\n",
    "    \n",
    "    \n",
    "    freq_step = f_sine/samp_freq\n",
    "    SINE_TABLE = np.sin(2*np.pi*n*freq_step) * MAX_SINE\n",
    "\n",
    "    return SINE_TABLE, MAX_SINE, LOOKUP_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### direct component explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####explain idea of modulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### explanation about the c board"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The init function provides all the state variables and creates the SIN table.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# state variables\n",
    "def init(f_sine, samp_freq):\n",
    "    global sine_pointer\n",
    "    global x_prev\n",
    "    global GAIN\n",
    "    global SINE_TABLE\n",
    "    global MAX_SINE\n",
    "    global LOOKUP_SIZE\n",
    "\n",
    "    GAIN = 1\n",
    "    x_prev = 0\n",
    "    sine_pointer = 0\n",
    "    \n",
    "    # compute SINE TABLE\n",
    "    SINE_TABLE, MAX_SINE, LOOKUP_SIZE  = build_sine_table(f_sine, samp_freq, data_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The process function takes the input buffer (raw voice) and fills the output buffer with the pitch shiffted voice.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process(input_buffer, output_buffer, buffer_len):\n",
    "\n",
    "    # specify global variables modified here\n",
    "    global x_prev\n",
    "    global sine_pointer\n",
    "\n",
    "    for n in range(buffer_len):\n",
    "        \n",
    "        # high pass filter\n",
    "        output_buffer[n] = input_buffer[n] - x_prev\n",
    "\n",
    "        # modulation\n",
    "        output_buffer[n] = output_buffer[n] * SINE_TABLE[sine_pointer]/MAX_SINE\n",
    "\n",
    "        # update state variables\n",
    "        sine_pointer = (sine_pointer+1)%LOOKUP_SIZE\n",
    "        x_prev = input_buffer[n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can use this functions either in real-time or to process a wav file. Here is the main function for a wav file:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "You can tweak the following parameters to play with the function\n",
    "\"\"\"\n",
    "buffer_len = 256\n",
    "modulation_freq = 350\n",
    "input_wav = \"speech.wav\"\n",
    "\n",
    "\n",
    "samp_freq, signal = wavfile.read(input_wav)\n",
    "\n",
    "# If the wav file has several channels, just pick one of them\n",
    "if len(signal.shape)>1 :\n",
    "    signal = signal[:,0]\n",
    "    \n",
    "n_buffers = len(signal)//buffer_len\n",
    "data_type = signal.dtype\n",
    "\n",
    "# allocate input and output buffers\n",
    "input_buffer = np.zeros(buffer_len, dtype=data_type)\n",
    "output_buffer = np.zeros(buffer_len, dtype=data_type)\n",
    "\n",
    "\"\"\"\n",
    "Nothing to touch after this!\n",
    "\"\"\"\n",
    "\n",
    "init(modulation_freq, samp_freq)\n",
    "signal_proc = np.zeros(n_buffers*buffer_len, dtype=data_type)\n",
    "\n",
    "for k in range(n_buffers):\n",
    "\n",
    "    # index the appropriate samples\n",
    "    input_buffer = signal[k*buffer_len:(k+1)*buffer_len]\n",
    "    process(input_buffer, output_buffer, buffer_len)\n",
    "    signal_proc[k*buffer_len:(k+1)*buffer_len] = output_buffer\n",
    "\n",
    "# write to WAV\n",
    "wavfile.write(\"speech_mod.wav\", samp_freq, signal_proc)\n",
    "print(\"Done !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Right below is the code you can use to transform your own voice in real time.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################################################\n",
      "press Return to quit\n",
      "################################################################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "buffer_len = 256\n",
    "modulation_freq = 500\n",
    "data_type = np.int16\n",
    "samp_freq = 44100\n",
    "\n",
    "try:\n",
    "    sd.default.samplerate = 16000\n",
    "    sd.default.blocksize = buffer_len\n",
    "    sd.default.dtype = data_type\n",
    "\n",
    "    def callback(indata, outdata, frames, time, status):\n",
    "        if status:\n",
    "            print(status)\n",
    "        process(indata[:,0], outdata[:,0], frames)\n",
    "\n",
    "    init(modulation_freq, samp_freq)\n",
    "    with sd.Stream(channels=1, callback=callback):\n",
    "        print('#' * 80)\n",
    "        print('press Return to quit')\n",
    "        print('#' * 80)\n",
    "        input()\n",
    "except KeyboardInterrupt:\n",
    "    parser.exit('\\nInterrupted by user')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 3: GRANULAR SYNTHESIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main idea : the resampling technique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this method, the pitch shifting is not achieved by an *explicit* modulation like the one used for the robot voice.\n",
    "\n",
    "\n",
    "Based on the input signal, the goal is to **create and use new samples at a higher rate through interpolation**.\n",
    "\n",
    "Concretely, those new samples will be separated by a period $T_s'$ that is smaller than the original period $T_s$.\n",
    "\n",
    "Let's take an example. Suppose the pitch factor is 0.75, ie you want to have a deeper voice.\n",
    "\n",
    "- The first block of data contains 10 samples at times $[0,1,2,3,4,5,6,7,8,9]$  $ ms$\n",
    "\n",
    "- The output will contain interpolated values of the input at times $0.75 \\times [0,1,2,3,4,5,6,7,8,9]$  $ ms$\n",
    "\n",
    "**We must note 3 things here**:\n",
    "\n",
    "\n",
    "- Note 1: The interpolation is **linear**. So, $interpolatedValue(t=2.25)$ = $0.75 \\times input(t=2) + 0.25 \\times input(t=3)$ \n",
    "\n",
    "\n",
    "- Note 2: The last interpolation time is $t = 9 \\times 0.75 = 6.75$. So there might be **losses of information** (raw samples at times $t = [7,8,9]$).\n",
    "\n",
    "\n",
    "- Note 3: The 10 output samples will be played at the **same rate $f_s$** than the one of the 10 input samples.\n",
    "\n",
    "$\\to$ It would initially take $6.75$ $ms$ to play the information embedded in the $[0,6.75]$ interval. In the output, it takes now $9$  $ ms$ to play the same information.\n",
    "    \n",
    "    \n",
    "With this example, we can see that **the audio has been _stretched_ by a factor 0.75**, making the output sound deeper than the original."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Because of the loss of information, there might be discontinuities between output blocks. **\n",
    "\n",
    "\n",
    "This is an annoying artifact since discontinuities in an audio file result in \"tick\" noises that alter the overall audio quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution : use overlapping grains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trick is to use overlapping chunks of samples that are called $grains$. \n",
    "\n",
    "Be careful : here, overlapping does not mean that output samples are a mix between consecutive input blocks.\n",
    "\n",
    "Instead, it means that **some raw samples will be processed twice in row.**\n",
    "\n",
    "- The first time as the last samples of a grain\n",
    "- The second time as the first samples of the next grain\n",
    "\n",
    "---------\n",
    "As in the previous example, interpolated values are computed for each grain at times $grainStart + k \\times shiftFactor \\times T_s$ \n",
    "\n",
    "- $T_s$ the sampling period\n",
    "- $k$ an integer number ranging from 0 to the number of samples in the grain.\n",
    "\n",
    "\n",
    "--------------------------\n",
    "\n",
    "\n",
    "**Important :** Where two grains overlap, two \"families\" of interpolated values are computed (ie one for each grain). In other words, there will be two different interpolated values for the same output value. Hence, it is necessary to find a way of **combining those two values** so that there is not brutal discontinuity between output samples. This is achieved by using a **tapering window**.\n",
    "\n",
    "A tapering window is simply an array that associates a multiplicative factor to each resampled (ie interpolated) value.\n",
    "- For zones with no overlap, this factor is simply 1\n",
    "- For zones with overlap, this factor is a number in $[0,1]$ that follows a linear function\n",
    "    - This function is increasing for reampled values at the start of a grain\n",
    "    - This function is decreasing for resampled values at the end of a grain\n",
    "\n",
    "\n",
    "**Concretely :**\n",
    "When there are two different resampled values for the same output sample:\n",
    "- $resampled\\_value_1$ is scaled by the tapering window of its grain evaluated at time $t=output\\_sample\\_time$\n",
    "- $resampled\\_value_2$ is scaled by the tapering window of its grain evaluated at time $t=output\\_sample\\_time$\n",
    "- output sample = $scaled\\_resampled\\_value_1$ + $scaled\\_resampled\\_value_2$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "As an image is worth a thousand words, let's have a look at the following example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://i.postimg.cc/ZqLH95hQ/resampling-times.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://i.postimg.cc/ZqLH95hQ/resampling-times.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the figure above, each square represents 1 time unit ($TU$).\n",
    "\n",
    "- The input samples are represented in dark blue. We can see that $T_s=6$  $TU$\n",
    "- The pitch shifting factor is $\\frac{11}{12}$ so this implies that $T_s'=5.5$ $TU$\n",
    "\n",
    "For both grains, we can see that resampling times (pink and light blue ticks on the x-axis) are placed at integer multiples of $T_s'$ from the start of the grains.\n",
    "\n",
    "We can see that the **raw** samples at times $t=[36, 42, 48, 54]$ $TU$ belong to two different grains and will thus be processed twice.\n",
    "- The first time to compute $sample_{pink}(t= [38.5, 44, 49.5])$\n",
    "- The second time to compute $sample_{blue}(t= [41.5, 47, 52.5])$\n",
    "\n",
    "**Note** :\n",
    "- Here we only show the first two grains of the audio stream, so the first samples of $grain_1$ are exclusively used for $grain_1$ (since there is no $grain_0$ !)\n",
    "- With the same idea, the last samples of the last grain of the audio stream will also be used exclusively for this last grain.\n",
    "\n",
    "-------------\n",
    "\n",
    "On the figure below, you can see all the resampled (interpolated) values computed for every resample time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://i.postimg.cc/KYbQvgCL/resampled-values.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"https://i.postimg.cc/KYbQvgCL/resampled-values.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last thing to do in this example is to scale and merge the interpolated values of $grain_1$ and $grain_2$ that overlap.\n",
    "\n",
    "**Concretely** :\n",
    "- $sample_{pink}(t=38.5)$ and $sample_{blue}(t=41.5)$ must be merged to compute $sample_{output}(t=42)$\n",
    "\n",
    "\n",
    "- As $window_{pink}(t=42) = \\frac{2}{3}$ and $window_{blue}(t=42) = \\frac{1}{3}$\n",
    "\n",
    "\n",
    "- $sample_{output}(t=42)$ =  $window_{pink}(t=42) \\times sample_{pink}(t=38.5) + window_{blue}(t=42) \\times sample_{blue}(t=41.5)$\n",
    "\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$= \\frac{2}{3} \\times sample_{pink}(t=38.5) + \\frac{1}{3} \\times sample_{blue}(t=41.5)$ \n",
    "\n",
    "\n",
    "--------------------\n",
    "**Important Note, do not forget that the samples blocs arrive one after the other ! This implies that :** \n",
    "- In order to compute the output samples corresponding to the last raw samples of the grain, it is necessary to wait for the next sample block. When the latter arrives, the second grain can be formed and the output sample can finally be computed, as all the overlapping samples (ex : pink **and** light blue) are available.\n",
    "\n",
    "\n",
    "- Each newly arrived sample bloc needs to have access to:\n",
    "    1. The last **raw** samples of the preceding bloc $\\to$ build the new grain\n",
    "    2. The last resampled values (pink) of the preceding bloc $\\to$ compute the output samples for the overlapping part at the start of this new grain.\n",
    "    \n",
    "    \n",
    "**In our example **: Everytime a block arrives, only $6$ output samples can be directly computed. The remaining $3$ resampling values at the end of the block need to be combined with the first $3$ resampling values that will be computed in the next grain.\n",
    "\n",
    "${\\to}$ This value $6$ is refered to as *the stride*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From theory to implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now that the algorithm has been explained, it is time to understand the implications of every constraint in the implementation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Constant parameters\n",
    "\n",
    "- Number of samples in a grain $\\to$ $GRAIN\\_LEN\\_SAMP$\n",
    "- Number of output samples that can be produced without the need of the next grain $\\to$ $STRIDE$\n",
    "- The tapering window of length $GRAIN\\_LEN\\_SAMP$ $\\to$ $WIN$\n",
    "    - In fact the length of the mixing edges of the window can be modified (it will obviously modify $STRIDE$ value )\n",
    "\n",
    "Interpolation :\n",
    "- Resampling times with respect to the start of the grain (pink and light-blue time indices) $\\to$ $SAMP\\_VALS$\n",
    "- The amplitude factor associated to the preceding raw sample for each resampling time $\\to$ $AMP\\_VALS$ (necessary to perform linear interpolation)\n",
    "\n",
    "- In this example : $interpolatedValue(t=2.25)$ = $0.75 \\times input(t=2)+0.25 \\times input(t=3)$,&nbsp;&nbsp;  $AMP\\_VALS(t=2.25) = 0.75$\n",
    "\n",
    "\n",
    "    \n",
    "###### What arrives at each iteration\n",
    "- A sample block of &nbsp;$STRIDE$&nbsp; samples\n",
    "\n",
    "\n",
    "###### To be passed between each sample blocks\n",
    "- The last raw samples of the previous block $\\to$ $PREVIOUS\\_RAW$\n",
    "    - Note : those samples concatenated with the &nbsp;$STRIDE$ samples of the coming block makes a full grain\n",
    "    \n",
    "    \n",
    "- The last fully processed resampled values (window scaling included) of the previous block $\\to$ $PREVIOUS\\_DOWN\\_WINDOWED$ \n",
    "\n",
    "###### Locally used variables\n",
    "\n",
    "- The grain formed by the incoming raw sample block concatenated with the $PREVIOUS\\_RAW$ samples $\\to$ $GRAIN$\n",
    "- The array containing the resampled values and then the window-scaled resampled values $\\to$ $RESAMPLED\\_GRAIN$"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Anaconda3]",
   "language": "python",
   "name": "Python [Anaconda3]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
